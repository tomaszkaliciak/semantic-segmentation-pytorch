{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('spam.dat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4789 entries, 0 to 4788\n",
      "Columns: 463 entries, ACT_NOW to target\n",
      "dtypes: int64(462), object(1)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "features.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT_NOW</th>\n",
       "      <th>ADDRESSES_ON_CD</th>\n",
       "      <th>ADULT_SITE</th>\n",
       "      <th>ADVERT_CODE</th>\n",
       "      <th>ADVERT_CODE2</th>\n",
       "      <th>ALL_CAPS_HEADER</th>\n",
       "      <th>ALL_CAP_PORN</th>\n",
       "      <th>ALL_NATURAL</th>\n",
       "      <th>AMATEUR_PORN</th>\n",
       "      <th>AMAZING</th>\n",
       "      <th>...</th>\n",
       "      <th>X_AUTH_WARNING</th>\n",
       "      <th>X_ENC_PRESENT</th>\n",
       "      <th>X_LIBRARY</th>\n",
       "      <th>X_LIST_UNSUBSCRIBE</th>\n",
       "      <th>X_MSMAIL_PRIORITY_HIGH</th>\n",
       "      <th>X_PRECEDENCE_REF</th>\n",
       "      <th>X_PRIORITY_HIGH</th>\n",
       "      <th>X_STORMPOST_TO</th>\n",
       "      <th>X_X_PRESENT</th>\n",
       "      <th>YOUR_INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.0</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "      <td>4789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.008144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.005638</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315097</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.012946</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.089883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077590</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.085185</td>\n",
       "      <td>0.043315</td>\n",
       "      <td>0.045653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464603</td>\n",
       "      <td>0.032298</td>\n",
       "      <td>0.025023</td>\n",
       "      <td>0.113055</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>0.138009</td>\n",
       "      <td>0.028892</td>\n",
       "      <td>0.035377</td>\n",
       "      <td>0.025023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ACT_NOW  ADDRESSES_ON_CD   ADULT_SITE  ADVERT_CODE  ADVERT_CODE2  \\\n",
       "count  4789.000000           4789.0  4789.000000  4789.000000   4789.000000   \n",
       "mean      0.008144              0.0     0.006056     0.000209      0.006682   \n",
       "std       0.089883              0.0     0.077590     0.014450      0.081478   \n",
       "min       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "25%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "50%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "75%       0.000000              0.0     0.000000     0.000000      0.000000   \n",
       "max       1.000000              0.0     1.000000     1.000000      1.000000   \n",
       "\n",
       "       ALL_CAPS_HEADER  ALL_CAP_PORN  ALL_NATURAL  AMATEUR_PORN      AMAZING  \\\n",
       "count      4789.000000   4789.000000  4789.000000   4789.000000  4789.000000   \n",
       "mean          0.000626      0.005638     0.007308      0.001879     0.002088   \n",
       "std           0.025023      0.074882     0.085185      0.043315     0.045653   \n",
       "min           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "25%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "50%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "75%           0.000000      0.000000     0.000000      0.000000     0.000000   \n",
       "max           1.000000      1.000000     1.000000      1.000000     1.000000   \n",
       "\n",
       "       ...  X_AUTH_WARNING  X_ENC_PRESENT    X_LIBRARY  X_LIST_UNSUBSCRIBE  \\\n",
       "count  ...     4789.000000    4789.000000  4789.000000         4789.000000   \n",
       "mean   ...        0.315097       0.001044     0.000626            0.012946   \n",
       "std    ...        0.464603       0.032298     0.025023            0.113055   \n",
       "min    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "25%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "50%    ...        0.000000       0.000000     0.000000            0.000000   \n",
       "75%    ...        1.000000       0.000000     0.000000            0.000000   \n",
       "max    ...        1.000000       1.000000     1.000000            1.000000   \n",
       "\n",
       "       X_MSMAIL_PRIORITY_HIGH  X_PRECEDENCE_REF  X_PRIORITY_HIGH  \\\n",
       "count             4789.000000       4789.000000      4789.000000   \n",
       "mean                 0.009397          0.000418         0.019420   \n",
       "std                  0.096489          0.020434         0.138009   \n",
       "min                  0.000000          0.000000         0.000000   \n",
       "25%                  0.000000          0.000000         0.000000   \n",
       "50%                  0.000000          0.000000         0.000000   \n",
       "75%                  0.000000          0.000000         0.000000   \n",
       "max                  1.000000          1.000000         1.000000   \n",
       "\n",
       "       X_STORMPOST_TO  X_X_PRESENT  YOUR_INCOME  \n",
       "count     4789.000000  4789.000000  4789.000000  \n",
       "mean         0.000835     0.001253     0.000626  \n",
       "std          0.028892     0.035377     0.025023  \n",
       "min          0.000000     0.000000     0.000000  \n",
       "25%          0.000000     0.000000     0.000000  \n",
       "50%          0.000000     0.000000     0.000000  \n",
       "75%          0.000000     0.000000     0.000000  \n",
       "max          1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 462 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "labelEncoder.fit(['no','yes'])\n",
    "features.loc[:,'target'] = labelEncoder.transform(features['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACT_NOW            0\n",
       "ADDRESSES_ON_CD    0\n",
       "ADULT_SITE         0\n",
       "ADVERT_CODE        0\n",
       "ADVERT_CODE2       0\n",
       "                  ..\n",
       "X_PRIORITY_HIGH    0\n",
       "X_STORMPOST_TO     0\n",
       "X_X_PRESENT        0\n",
       "YOUR_INCOME        0\n",
       "target             0\n",
       "Length: 463, dtype: int64"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()\n",
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAt8AAAFRCAYAAACsWMHxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deZglVX3/8feHRVBxQUFEFkHFGFwgOiJGMSguSDToT2MwLrhETJREE43ijvsSjNFEjBgRXCLBFYLIKopGEQZFEJAwUZAZWYZVUEHA7++Pcxovl+6e7pme6p7h/Xqe+/StU6eqzq17e+ZzT586lapCkiRJ0uq3znw3QJIkSbq9MHxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEvSFJK8KEmNPH6V5IIkX0nynCRZTcfdNcn+Seb83+je/s/O9X5XcMxDklwwR/vapr8Xf7WCet9M8s25OKYkzSXDtySt2J8Djwb2AN4C3AB8Hjg+yR1Xw/F2Bd7G2vNv9DuBZ853IyRpIVhvvhsgSWuAM6pqycjyZ5J8AfgC8AHgb+enWZBkfeCmWsB3TKuq/5vvNkjSQrG29KpI0qCq6kvAEcDLktwpyQZJlif50HjdkeErD+rLj0xyfJIrkvwmyU+THNjX7U/r9Qa4cWLIS183MeTiFUk+kOQXtF74h/fyPSc59iFJliZZd6z8ZUmWJLk+yQ+SPH5s/aTDNvqwlUPGyrZN8pkklyS5ob+eD4+14YKxbd7ej/vLJJcn+UaSnSc/29NLskmS7yc5N8nWU9TZMMmHkvw4yXW9rf898Z6M1Lt3kkOT/KK/louTHJXkXivTNkkaZ8+3JK28o4FnAIuq6uQknwJemuQNVXX9SL2XA9+qqp8k2Qg4FjgVeBFwLbAN8Me97n8AWwIvBR4L3DzJcd8EnAbsA6wLnNOXX077QgBAkrsDzwE+UFWj+9kVeETfzw3A64GvJ9mhqs6bzQlIsm1/Lb8G3gqcD2wNPHkFm24BfAhYCtwZeD5wcpJHVNVZszj+NrTzeRXw2Kq6YoqqGwB3Ad4FXAzcA3gF8L0kf1hVl/R6nwHuC/wjcBGwGbAbcKeZtkmSpmP4lqSV9/P+c/P+89+B19DGiH8GIMnDgJ2B5/Y6DwI2Bl5XVWeO7OsQgKpammRpL/t+Vd00yXEvBZ45OtSk95x/Msl9q+rCXvxC4A60QD/qXsCjq+qivu2JwIXAm4EXzOyl3+LtwB2BHarqFyPlh063UVXdcsFk75U/Bjgb+CvgVTM5cJIdgK8DZwDPrqpfT3O8a/q+R495LO1cPpf2RQDa2P43VtXnRjb/wkzaI0kz4bATSVp5E7OdFEBV/ZQW6F4+UuflwHLgy335fOBq4ONJnp9kq5U47lcnGeN9WN/vy8aO/bWqWjpW95SJ4N3bfS3wNVrwnK0nA0eNBe8VSvLEJCcluQK4CbgReCDwBzPcxeOAbwEnAH82XfAeOeZz+vCUq/sxfwVsNHbM04B/TPKqJA9dXTPaSLr9MnxL0sqbCM4Xj5QdCDwmyUOSTAyn+FRV/RZu6YF9PPCLXvfnfRzys2Zx3IvHC/owl08BL0myXpJdgO1pvfHjLp2ibItZtGHCPWlDR2YsycNpQ3auow2v2Rl4JPAjYMMZ7mYPWnD++BR/HRg/5tOB/wLOBf4SeFQ/5vKxY/4FcCTwOuBMYFmSt66OaR8l3T457ESSVt6fAtcDp4+UHQ1cQOt1/hFtnPFBoxtV1RnAs5KsBywC3gAc3sdc/3gGx51qZpOPAf8A7Emb2u8CWk/8uM2mKFs2snw9cNdJ6t1jbPlyZh/an0Xref5/VXXjRGGSjWm99zPxFlqv+9eTPLWq/mcF9fcCllTVi0aOtz5jr6eqLgNeCbwyyR8Ae9OG1iynnV9JWiV+k5ekldB7qv8M+PfRIQ9V9Tvg47Sx0/sCJ0w11V5V3VRVp9CC5DrAH/ZVN/Sfs5pDvB/nONrFgs8GPtHbM27n0eEuSe5C+yLxvZE6FwIPTHKHkXqPo32ZGHUc8LQkmzNzd6JdSDo6Zv0JtAs1Z+pG2sWkxwHH9J7+FR1zvIf8BbQLVidVVedV1RtpF3M+ZBZtk6Qp2fMtSSu2Y5JNaBcvbg08jXZR5fG0XutxnwT2B3ag9fLeIsnTaLOUfBX4GW2mj7+jzXoyEX7P6T9fk+TrwM1VtXiGbT2QNuPJjb0dk7kUOK5Pazgx28mdaTfDmXBYb+fBfWrBbWm96teM7etttCEg303yHmAJrSd896p6/hTHPwZ4NXBInyHmgbQvIMumqD+pqroxyV7A52g94HtU1cnTHPMZaVNBHkX7i8PfMtLTnuRutDHknwN+QjuHe9IukD1uNm2TpKkYviVpxSZmu7geuAz4AW0Ywxcnu7lNVS1P8i3gobTxw6POB35DC5ub00L3acCTRi6MPIoWol9Bm74v/P7izhX5Wt//16pqsrHd0C5U/CbwHtq0hucAT62q/x15DScl+WvgtbQvED+kjV//0thrvaDPz/0u4L20cdjLGJnycKLqyDbHJvk7Wph/FvBj2swsb57haxw9/k1J/pI2u8zXkzytqk6apOonaGP0X0IbEnQa8HTgKyN1rqe9ty+jTTf4O+A84HlVNf56JGmlZAHfFE2S1kh97PLPgX+pqrcMfOwn0Xppn1hVJw557Kkk+TKwdVUtmu+2SNJ8s+dbkuZIkk1p09a9ijaG+8ABj31/4H60+ap/sBCCd5L7AI+hze7yuRVUl6TbBS+4lKS586fAt4GdgL2r6jZTAq5Gb6HdcOYG2hCOheA5tBv8nAy8Y57bIkkLgsNOJEmSpIHY8y1JkiQNxPAtSZIkDeR2c8HlJptsUttss818N0OSJElrudNPP/3yqtp0snW3m/C9zTbbsHjxTO9RIUmSJK2cJBdOtc5hJ5IkSdJADN+SJEnSQAzfkiRJ0kAGDd9JNkxyapIfJTk7ydt7+bZJvp9kSZL/SnKHXr5BX17S128zsq839PLzkjxlyNchSZIkrYyhe75vAJ5QVTsAOwK7J9kZeD/woap6AHAV8NJe/6XAVb38Q70eSbYH9gIeDOwOHJhk3UFfiSRJkjRLg4bvaq7ri+v3RwFPAL7Yyw8FntGf79mX6et3S5JeflhV3VBVPwOW0G7nLEmSJC1Yg4/5TrJukjOAy4Djgf8Drq6qm3qVpcAW/fkWwEUAff01wD1HyyfZZvRY+yRZnGTx8uXLV8fLkSRJkmZs8PBdVTdX1Y7AlrTe6getxmMdVFWLqmrRpptOOs+5JEmSNJh5m+2kqq4GTgIeDdw9ycQNf7YElvXny4CtAPr6uwFXjJZPso0kSZK0IA0928mmSe7en98ReBJwLi2EP7tX2xs4oj8/si/T13+jqqqX79VnQ9kW2A44dZhXIUmSJK2coW8vvzlwaJ+ZZB3g8Ko6Ksk5wGFJ3gX8EPhkr/9J4DNJlgBX0mY4oarOTnI4cA5wE/DKqrp54NciSZIkzUpaR/Lab9GiRbV48eL5bgZP+9xr57sJktYQRz3vgPlugiRpJSQ5vaoWTbbOO1xKkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMxfEuSJEkDMXxLkiRJAzF8S5IkSQMZNHwn2SrJSUnOSXJ2klf18v2TLEtyRn/sMbLNG5IsSXJekqeMlO/ey5Yk2W/I1yFJkiStjPUGPt5NwGuq6gdJ7gKcnuT4vu5DVXXAaOUk2wN7AQ8G7gOckOSBffVHgScBS4HTkhxZVecM8iokSZKklTBo+K6qi4GL+/Nrk5wLbDHNJnsCh1XVDcDPkiwBdurrllTVTwGSHNbrGr4lSZK0YM3bmO8k2wB/BHy/F+2b5MwkByfZuJdtAVw0stnSXjZV+fgx9kmyOMni5cuXz/ErkCRJkmZnXsJ3ko2ALwGvrqpfAh8D7g/sSOsZ/+BcHKeqDqqqRVW1aNNNN52LXUqSJEkrbegx3yRZnxa8P1dVXwaoqktH1n8COKovLgO2Gtl8y17GNOWSJEnSgjT0bCcBPgmcW1X/PFK++Ui1ZwI/7s+PBPZKskGSbYHtgFOB04Dtkmyb5A60izKPHOI1SJIkSStr6J7vxwAvAM5KckYveyPw3CQ7AgVcALwcoKrOTnI47ULKm4BXVtXNAEn2BY4F1gUOrqqzh3whkiRJ0mwNPdvJd4BMsuroabZ5N/DuScqPnm47SZIkaaHxDpeSJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAYN30m2SnJSknOSnJ3kVb38HkmOT3J+/7lxL0+SjyRZkuTMJA8f2dfevf75SfYe8nVIkiRJK2Ponu+bgNdU1fbAzsArk2wP7AecWFXbASf2ZYCnAtv1xz7Ax6CFdeBtwKOAnYC3TQR2SZIkaaEaNHxX1cVV9YP+/FrgXGALYE/g0F7tUOAZ/fmewKerOQW4e5LNgacAx1fVlVV1FXA8sPuAL0WSJEmatXkb851kG+CPgO8Dm1XVxX3VJcBm/fkWwEUjmy3tZVOVS5IkSQvWvITvJBsBXwJeXVW/HF1XVQXUHB1nnySLkyxevnz5XOxSkiRJWmmDh+8k69OC9+eq6su9+NI+nIT+87JevgzYamTzLXvZVOW3UlUHVdWiqlq06aabzu0LkSRJkmZp6NlOAnwSOLeq/nlk1ZHAxIwlewNHjJS/sM96sjNwTR+ecizw5CQb9wstn9zLJEmSpAVrvYGP9xjgBcBZSc7oZW8E3gccnuSlwIXAc/q6o4E9gCXAr4EXA1TVlUneCZzW672jqq4c5iVIkiRJK2fQ8F1V3wEyxerdJqlfwCun2NfBwMFz1zpJkiRp9fIOl5IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kCGvr28JEmz9rTPvXa+myBpDXHU8w6Y7yZMy55vSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCzCt9J1k9y5ynW3TnJ+nPTLEmSJGntM234TvL+saL/AD4xRfWP94ckSZKkSayo53uvJF9MsmFffjxwxBR1jwR2m7OWSZIkSWuZFYXvHYF1gZP78r2Ay6aouxzYbI7aJUmSJK11pg3fVXVVVT0TOKQXXQY8dIrqDwWumLumSZIkSWuXGV1wWVUH9qdHAW9J8rDR9UkeCrwJ+O+5bZ4kSZK09lhvlvXfCjwJOD3JacBSYAtgJ+BnwJvntnmSJEnS2mNWUw1W1eXAI4H3AqGNCQ/wbuCRfb0kSZKkScy255uquprWA/7WuW+OJEmStPaaVfhOsg6wTlXdNFL2FOAhwDeq6odz3D5JkiRprbGim+wcnmSDkaLPAwePrP9r4OvAPwGnJHniammlJEmStBZY0ZjvBwAnJblnX94ZOHpk/T/S7np5N+DLtBlPJEmSJE1iReH7UcCpwPf78r2AZQBJHgBsC/xbVV0LfIqp5wCXJEmSbvemHfNdVTcCr05yXC/6JTDRC74rcHlVndmXbwY2RJIkSdKkZnTBZVVNDDX5LrBfkpuAV3PrISgPoM37LUmSJGkSs5rnG3gdref7SFov9/4j6/4C+N50Gyc5OMllSX48UrZ/kmVJzuiPPUbWvSHJkiTn9VlVJsp372VLkuw3y9cgSZIkzYtZTTVYVecD2yW5Z1VdMbb6VcAlK9jFIcC/AZ8eK/9QVR0wWpBke2Av4MHAfYATkjywr/4o7U6bS4HTkhxZVefM5rVIkiRJQ5v1TXYAquqKJBsBGwNXVdV1VXXWDLY7Ock2MzzMnsBhVXUD8LMkS2i3sQdYUlU/BUhyWK9r+JYkSdKCNtthJyR5SpLFwNXABcDVSU5N8qRVaMe+Sc7sw1I27mVbABeN1Fnay6YqlyRJkha0WYXvPu76a8BGwDuBVwDvAu4CHL2SAfxjwP2BHYGLgQ+uxD4mlWSfJIuTLF6+fPlc7VaSJElaKbMddrI/cBzwtKr63URhkncARwFvB46fzQ6r6tKR/Xyi7wfafOJbjVTdspcxTfn4vg8CDgJYtGhRzaZdkiRJ0lyb7bCTHYCPjgZvgL58IK33elaSbD6y+ExgYiaUI4G9kmyQZFtgO9oNf06jXfS5bZI70C7KPHK2x5UkSZKGNtue7xuAu06x7i59/ZSSfJ52c55NkiwF3gbsmmRHoGhjyF8OUFVnJzmcdiHlTcArq+rmvp99gWOBdYGDq+rsWb4OSZIkaXCzDd/fBN6Z5JSq+tlEYZKtaUNSTppu46p67iTFn5ym/ruBd09SfjS3vsGPJEmStODNNny/Hvgf4Lwkp9AukLw3sDNt9pPXz23zJEmSpLXHrMZ8V9X/Ag8DPgJsADycdqfLDwM79pvwSJIkSZrErG+yU1UXA69dDW2RJEmS1mqzvsmOJEmSpJWzwp7vJN+Yxf6qqnZbhfZIkiRJa62ZDDtZhzYN4ExkFdoiSZIkrdVWGL6ratcB2iFJkiSt9WYy7OR+s9lhVf105ZsjSZIkrb1mMuxkCTMbdpJeb91VapEkSZK0lppJ+H7xam+FJEmSdDswkzHfhw7REEmSJGlt5zzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAzfkiRJ0kAM35IkSdJADN+SJEnSQAYN30kOTnJZkh+PlN0jyfFJzu8/N+7lSfKRJEuSnJnk4SPb7N3rn59k7yFfgyRJkrSyhu75PgTYfaxsP+DEqtoOOLEvAzwV2K4/9gE+Bi2sA28DHgXsBLxtIrBLkiRJC9mg4buqTgauHCveEzi0Pz8UeMZI+aerOQW4e5LNgacAx1fVlVV1FXA8tw30kiRJ0oKzEMZ8b1ZVF/fnlwCb9edbABeN1Fvay6YqlyRJkha0hRC+b1FVBdRc7S/JPkkWJ1m8fPnyudqtJEmStFIWQvi+tA8nof+8rJcvA7YaqbdlL5uq/Daq6qCqWlRVizbddNM5b7gkSZI0GwshfB8JTMxYsjdwxEj5C/usJzsD1/ThKccCT06ycb/Q8sm9TJIkSVrQ1hvyYEk+D+wKbJJkKW3WkvcBhyd5KXAh8Jxe/WhgD2AJ8GvgxQBVdWWSdwKn9XrvqKrxizglSZKkBWfQ8F1Vz51i1W6T1C3glVPs52Dg4DlsmiRJkrTaLYRhJ5IkSdLtguFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGojhW5IkSRqI4VuSJEkaiOFbkiRJGsiCCd9JLkhyVpIzkizuZfdIcnyS8/vPjXt5knwkyZIkZyZ5+Py2XpIkSVqxBRO+u8dX1Y5Vtagv7wecWFXbASf2ZYCnAtv1xz7AxwZvqSRJkjRLCy18j9sTOLQ/PxR4xkj5p6s5Bbh7ks3no4GSJEnSTC2k8F3AcUlOT7JPL9usqi7uzy8BNuvPtwAuGtl2aS+TJEmSFqz15rsBIx5bVcuS3As4PslPRldWVSWp2eywh/h9ALbeeuu5a6kkSZK0EhZMz3dVLes/LwO+AuwEXDoxnKT/vKxXXwZsNbL5lr1sfJ8HVdWiqlq06aabrs7mS5IkSSu0IMJ3kjsnucvEc+DJwI+BI4G9e7W9gSP68yOBF/ZZT3YGrhkZniJJkiQtSAtl2MlmwFeSQGvTf1bVMUlOAw5P8lLgQuA5vf7RwB7AEuDXwIuHb7IkSZI0OwsifFfVT4EdJim/AthtkvICXjlA0yRJkqQ5syCGnUiSJEm3B4ZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSCGb0mSJGkghm9JkiRpIIZvSZIkaSBrdPhOsnuS85IsSbLffLdHkiRJms4aG76TrAt8FHgqsD3w3CTbz2+rJEmSpKmtseEb2AlYUlU/rarfAocBe85zmyRJkqQprTffDVgFWwAXjSwvBR41WiHJPsA+ffG6JOcN1DZptjYBLp/vRmhhyfM/ON9NkBY6/+3UbSyQfzvvO9WKNTl8r1BVHQQcNN/tkFYkyeKqWjTf7ZCkNYn/dmpNtCYPO1kGbDWyvGUvkyRJkhakNTl8nwZsl2TbJHcA9gKOnOc2SZIkSVNaY4edVNVNSfYFjgXWBQ6uqrPnuVnSynJ4lCTNnv92ao2TqprvNkiSJEm3C2vysBNJkiRpjWL4liRJkgZi+JYkSZIGssZecCmtqZI8iHY31i160TLgyKo6d/5aJUmShmDPtzSgJK8HDgMCnNofAT6fZL/5bJskramSvHi+2yDNlLOdSANK8r/Ag6vqxrHyOwBnV9V289MySVpzJfl5VW093+2QZsJhJ9KwfgfcB7hwrHzzvk6SNIkkZ061CthsyLZIq8LwLQ3r1cCJSc4HLuplWwMPAPadt1ZJ0sK3GfAU4Kqx8gDfHb450soxfEsDqqpjkjwQ2IlbX3B5WlXdPH8tk6QF7yhgo6o6Y3xFkm8O3xxp5TjmW5IkSRqIs51IkiRJAzF8S5IkSQMxfEvSSkiya5Ibkjx1vtuyJkpy7ySXJnnHNHW2T/KrJHsP2TZJWp0M39I8SVIzeFww3+2cTpLDkvxkDvf3viTXz9X+Vpck9wQ+C/x9VX19lttekuTfZ7nNhkmuT3LgJOtO6p+VJ4yVb5Lkd0neNZtjraAd+yR5/hzsJ8CngROq6q1T1NkQ+C/gX6rq0BXs735JPprk+/08VZJNVrWdkrQ6ONuJNH8ePbb8FeBHwP4jZTcM1pqV82bgzvPdiHnwKeDwqrpNGJ6BPbjtVGnTqqrrk5wGPG60vN+c6VHAr/u6b4ys3oU2BdvJK9HGqewDXE774rEqXgfcEXjJNHU+BPyE9hlbke2BZwKn06ace/wqtk+SVhvDtzRPquqU0eUkNwCXj5cvZFW1ZL7bMB+q6s9WYdsfrOSm3wLemOSeVXVFL3sksAFwIGPBvC/fxBzMf5xkg6qasy+CVfV+4P0rqPM3s9jl0VV1H4Akr8bwLWkBc9iJtMAleVOSXye5+1j5ukmWJjmkLz+o/7n9r5L8a5LL+3jZI5JsNYNjXJNk3ZGyr/X9PXak7G/7OOc79uXbDDtJ8t4kZyT5ZZLlSU5IsmiSY+6U5Lt9mMBFSfabom13T/KxPlzjt0l+kmTfsTq797bukeSTSa5KcmWSDyRZJ8kfJ/leP49njQ/R6Pt4cV93Q2/3p5Lca6zOi5L8qJ/Xa/rzl4zVeWKSE/vrv66fixeOrJ/1sJPuZFpP9i4jZY+j/bXka8DOSdYfW/eDqrquH/cu/XNxbm//L5J8Jcn9x9q/bz+Xj+qfnWtoN4ZaDDwCeMrIsKijRrbbJck3+76vTXJMkh3H9v3YPkzmqv5eLEnywbE6D+yfq8v6Z2NJkvdNd2KqapXuDptk6ySfT3JFP+YPkvz5yPqHZOqhYUf1Ohv15TckeV2Sn/fPwAlJths73tOTHNs/C7/qn7tXJllnrF76+3Fmkt/0z/SJSR7R118+RZuum+2xpjgvf5Y2lOeX/T09N8k/jqw/oJ+vHZJ8u7dxaZI3JslIvdl+9h6R5Kv99+fitC9UJNmzn4tfpf0+P3Sm77G0kNjzLS18/wG8DXgh8JGR8qfRbtQzHuTeBpzW698HeC/w9SQ7THMjn5OAd9HC1alJ1qOFvN8ATwC+0+s9ATilqn4zTXvvDfwT7eZBdwFeBHwnyY5V9RNoF9sBJwAXAi8AbgZe39t7i96OY2nDCt5MG4awJ/CvSe5RVeMX630UOBx4DvBE2vCGO9Duivc+4FLasJ6vJLlvVV3dj/N3wIdpwyleR7vr6HuAnZIsqqrfJNmNNtzkg8A/0P793B645UtRkucAnwe+CbwMuAJ4KHDfac7XTH2X1pP9OOCrvexxwLf7ug1oPeHfTXJXYAfa0AaTSJ0AAAsnSURBVI0JdwbWp30+LgU2Bf4W+F6SP6iq8aEwhwOfoX3m1gEuBr4AXA38fa9zFUCSnYETgcW093Nd4C3At/v5Oy9tDPbRtM/a82lDZbYFHj5xwCQPAk6hDW15A/AzYBtu/YVjTqV9qf027XPyj8AltOEwhyd5flV9Dvg/bjtM7BHAvwHnjpW/HDgTeAWwEXAA8OUkD6vf31jjfsDXae/Pb2lDhw4ANqb9Hk74GG2oz7/Tzsc6wB8DW9KG2DyF9p5OuDvt8zf6F6mZHmv8vDwY+BJtbP5bgN8B2zH2O0p7r79K++vLO4E/A97dj3VArzPbz95/AgfTzu8LgA8l2QzYvR/jt7Tfwy8ledCqfvmSBldVPnz4WAAP4ALgs1OsOww4e6zsaOCMkeUHAQX8kH4DrV6+Wy9/3jTHXh+4Fnh9X96ZFvQ+DJzUy9YBrgT2H2vXT6bZ77p93xcA7x8p/yAt2N97pOxutGB3/UjZs3vb9xrb72dp4e1ufXn3Xu/AsXrn9PJFI2U79bK/6Mt3oIXkY8a2fWKvt09ffjPwixW81l8A/zN6/iepdwnw7yv5Gfk+sHjkeNcAz+7LPwD268+f2tv+9BW09260IPOykfJ9+7bvnGSbxePnqZcfQwtVdxop2wS4Dvh0X9617/d+07Tpy7RAf89V+D16dT/OJjOsv98kn5EA3wMunGKbLWhfLk8E1u9lG/X9nAmsM1L3Rb38YVPsK7Qvcu8Flo2UP6xv944Zvo71gON7u7aczbGmqPsi2pfi9aepc0Bv475j5Z/vv1N3XMnP3j+MlG0I/JL278XmI+V/2es+YmU/Kz58zNfDYSfSmuFAYPv0ISBJ7kvr9fr4JHW/UFW33Lq2qk6k9SSO99wxUudGWu/2xHCMJ9CC1leBR6fNPLEjrbfspOkamjYE5OQkV9AC/G9pPb9/MFLt0cC3q+qSkTZcQ+uhG/W4vv0Xxso/S7tgb6ex8vHtfwJcWVWLx8oAJobiPAS4B2MXEVbVCbRA+Se96DRg8ySHpA1vuevYsR4KbA58YvT8z7GTgR2T3IX2ftyV1msL7f2bGPf9OFpP5bdHN07ygiSLk/yS9t5cTftyNPreTPjKLNq1C/CVqvr1REFVXU4L5RPn7xzgV8Cnkjw3yXgPKsCTgC/V78e0D+FxwHmjn5H+/n0O2DrJtqOVk9wJOIIWCJ/Vf3dGHVO37ok9q//cemQfW6UNa7oIuLE/9gPuk2SjXu3J/edBM3wd/0rrFX96VS2d5bEmc3r/+YUkz0yb4Wcqh48tH0b7nbrlczXLz94tv8dVdT3ty/uZVXXxSJ3x32NpjWH4ltYAVXUy8GPgr3vRPrSe38lmnbh0irItVnCYk4DHpI0bfnxf/h6td+mPe9lvetmkkjwaOIrW6/ViWg/6I2n/UW44UnXzado56h7AZXXb4TKXjKwfNf7n699OUcZIeyb2cTG3dcnE+qo6FngucH9a+Lqij6V9cK87EU6W3mYvc+dkWq/hY2ih8fyqmjhn36a9f+v0dWdVH1YDkOS5tCEEp9OG5TyK9t5cx63fmwmTnY/b6F/M7jRF/dHzdxntS93VwCeAZWnj4f+072cDWu/x6jx/k7kHU7d9Yj1wyxSJn6F9mfzT0fM74sqx5YkLVTfs+1if9lerXWnDMHalvQ//PFqP9nkq2l9TppXkVbR/E55XIxf0zuJYt1FVZwF/Shsy8nngsiTf6b/jo34HLB8rm/hMbtHbMdvP3sr8HktrDMO3tOb4GPDsPl76JcDnq+raSeptNkXZshXs/yTaf7S70MLdN3qv0/dooekJwHer6rdT74Jn0/5DfXZVHVlV3+89iuMh+eJp2jnqSmDTSS4Ou/fI+lU1sY97T7Lu3qPHqKrDqmoX2ut5Nm088tf66sv7zxV9yVkV36aFncfx+/Heo+vuSvurwiJuO8XgXsCPqurlVXVMVZ0K/C8t8E5mRr33/TPya2Z2/k6tqj1pf0HZhRbSvpLkftVmU7mO1Xv+JnMlU7d9Yv2Ed9MC6TOq6qcrebyH9MffV9XBVfWdsb/MTLicNkxk8+l2lnaTpw/Shox9dWz1TI81qf45eRLt/dqddl3B1/tfXiasQxvDPWri93ji35zZfvaktZrhW1pzfIbW2/NftGAw1YwZfz4208ButPG3U/ZYdz+gjSF+I613deIiy2/QhgPswgqGnNB6QG9iJLgl2QO411i97wG79C8SE/XuRhurPOpbtP/wnzlW/jxaL/ypK2jPTPyYFrD2Gi3s520z2sWTt1JV11bVEcAngfv2ISg/pvVSvmz0/M+l3tN6Fm0ox2MZCd99CM//8fuLTL81tvmdaEMORr1olk24gTbcZ9zJwJ69Fxy45UZET2Hy83djVX0HeDu3HnpwHPCsJONf1lanbwEPytjMLLQxxRdW1c+gDZugDdd4aVX9zyoc70795y3vRdrsQX8xVu+4/nOfqXbU/+pyGHBwVR0wSZWZHmtaVfWbqjqedtHm3WgXfI56ztjyXrTfqfNG2rGqnz1preFsJ9IaoqquTfJZ4G+A02rq+aI3oc0C8B+0XrP3AmfT/pOebv83JzkZeDptPPbEjCYn0WYYgFvfxGUyx9CGxnyyt/UPgTdx2z/r/xNtNpDj024vfhMt2FzLrf+MfAQtYB/cxwifR5tN4fnA2/o48VVSVb9N8nbgw0k+RftyszWtl/Mc+tCetOnu7koLaxf3Oq+gzf7yy17n72nn+bgkn6ANv3kwcNeqmnRmiSR/QHt/3lhVH5hBk0+mXZgWxsZ09+W9R+qNOgY4IMl7aBcKPpr2HvyamTsHeG6S/wf8HLi62lzv+/djH582deB6/P7mOO+GW2aC2Qs4kjbLzV1ps8ZcRbu+ANoXv+8Dp/Tz/TPamN5dq2rKG/KkTZE58QVth/7z6UmuBS5eQVj+OO19PCrJm2m98S+mnZ/n9f0/mDZU5gjg//rsLhOuqqrzmLkzaENaDujDQtYBXgvc6s6uVXVWko8Db+5fZI7uq/6Ydv3B0cB/04Z8fHqsTTdX1WkzPdZk+md5R9psQ8toX0T3o70n549UvQl4TQ/1P6L9+7EX8NqRf0Pm4rMnrT3m+4pPHz58tAfTzHYyUufxtF7ll06ybmK2k7+iXXx1Oe0/tyOBrWbYhr/v+9h/pGxiJpRrgfXG6t9mthPgNbRw9RtakPoT2vRx47OJ7ESbIu8G4CLaf+zvY2S2k17v7rRe/ktoPf8/4bazK0zMdvLYSdq3ZKxsw173zWPlL6H1Kt9ACzSHAPcaWf8M2mwSl/Q6P6ddDLfZ2H6eTAvov+rn7IfA80fW32q2k5H3bb8ZvkfP6vVvM/NKfw0FnDvJuvVoX3ou6W07gfbF4HLg30bqTcw4ce9J9rF1PwfX9TpHjazbZeR1X0cLbTuOrH8Y8MX+2bieFnKPBP5oks/xF2k9p9fTgt57VnBOJmYamexx1HTbjryuw/oxb+jv2Z+PrH/aivY/0ob9xvb9kF7+7LHP/im038+f076g/h1js7TQvmC9ivbl7Abal7kTaNMzTvear5vtsSY5J39Cu35jWT/2L2gXod5vpM4B/T3agfaXst/0+m/i1jMurdJnj0lm2Rk5r3tN9Rp8+Fioj1StrovyJc213qv4UuA+NTKzRF/3INqcwy+oqlW9/bckTSvJAbQvwl70KM2Cw06kNUCSh9OGcPwN8C/jwVuSJK0ZDN/SmuFo2hjZo5nmrnSSJGlhc9iJJEmSNBCnGpQkSZIGYviWJEmSBmL4liRJkgZi+JYkSZIGYviWJEmSBmL4liRJkgby/wHkaYe/f7ycRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.countplot(x=features.target, color='mediumseagreen')\n",
    "plt.title('Dystrybucja klas', fontsize=16)\n",
    "plt.ylabel('Ilość', fontsize=16)\n",
    "plt.xlabel('Typ wiadomości. Wartość 1 oznacza spam', fontsize=16)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT_NOW: 0.10993674671036519\n",
      "ADDRESSES_ON_CD: nan\n",
      "ADULT_SITE: 0.09881525537548108\n",
      "ADVERT_CODE: 0.018295799989749104\n",
      "ADVERT_CODE2: 0.10383335531615924\n",
      "ALL_CAPS_HEADER: 0.014538472202316844\n",
      "ALL_CAP_PORN: 0.09532694196384595\n",
      "ALL_NATURAL: 0.10862578007013857\n",
      "AMATEUR_PORN: 0.0549333116460071\n",
      "AMAZING: 0.05791085267650537\n",
      "AMAZING_STUFF: 0.044838792594248764\n",
      "AOL_USERS_LINK: 0.05493331164600724\n",
      "APPLY_ONLINE: 0.021742769057671994\n",
      "APPROVED_BY: -0.16317414215980236\n",
      "ASCII_FORM_ENTRY: 0.03225317721172209\n",
      "ASKS_BILLING_ADDRESS: 0.044838792594248694\n",
      "AS_SEEN_ON: 0.17619462866631075\n",
      "BAD_CREDIT: 0.12307411589083916\n",
      "BALANCE_FOR_LONG_20K: 0.006052128698605897\n",
      "BALANCE_FOR_LONG_40K: -0.022838130478730796\n",
      "BANKRUPTCY: 0.031695875695884064\n",
      "BASE64_ENC_TEXT: 0.2938542940460415\n",
      "BEEN_TURNED_DOWN: 0.03719964112790706\n",
      "BEST_PORN: 0.07556187359947966\n",
      "BE_AMAZED: 0.036603068903139475\n",
      "BE_BOSS: 0.060743770305115796\n",
      "BIG_FONT: 0.4380895953966236\n",
      "BILL_1618: 0.07556187359947972\n",
      "BUGGY_CGI: 0.054933311646006996\n",
      "BUGZILLA_BUG: -0.07863930730885979\n",
      "BULK_EMAIL: 0.07776067450297144\n",
      "BUY_DIRECT: 0.025876870884120357\n",
      "CABLE_CONVERTER: 0.044838792594248646\n",
      "CALL_FREE: 0.06834375753485342\n",
      "CALL_NOW: 0.06604926541675578\n",
      "CARRIAGE_RETURNS: 0.10862578007013851\n",
      "CASHCASHCASH: 0.06604926541675597\n",
      "CBYI: 0.03169587569588402\n",
      "CELEBRITY_PORN: 0.05493331164600753\n",
      "CLICK_BELOW: 0.6331681680008769\n",
      "CLICK_BELOW_CAPS: 0.2920610758463988\n",
      "CLICK_HERE_CAPS_LINK: 0.2114724494614175\n",
      "CLICK_HERE_LINK: 0.4714030493525704\n",
      "CLICK_TO_REMOVE_2: 0.036603068903139566\n",
      "COMPETE: 0.03660306890313948\n",
      "COMPLAIN_TO: nan\n",
      "COMPLETELY_FREE: 0.14616786074599367\n",
      "CONGRATULATIONS: 0.05178620622000729\n",
      "CONSOLIDATE_DEBT: 0.10383335531615928\n",
      "COPY_ACCURATELY: 0.04483879259424878\n",
      "COUPON: 0.018295799989749128\n",
      "CREDIT_CARD: 0.05493331164600735\n",
      "CRON_ENV: -0.09756197756427647\n",
      "CTYPE_JUST_HTML: 0.5985798465969208\n",
      "CUM_SHOT: 0.025876870884120298\n",
      "DATE_IN_FUTURE_03_06: 0.15939693788771456\n",
      "DATE_IN_FUTURE_06_12: 0.17593194340867357\n",
      "DATE_IN_FUTURE_12_24: 0.12190926268424954\n",
      "DATE_IN_FUTURE_24_48: 0.06604926541675588\n",
      "DATE_IN_FUTURE_48_96: nan\n",
      "DATE_IN_FUTURE_96_XX: 0.018295799989749124\n",
      "DATE_IN_PAST_03_06: 0.06856372254575058\n",
      "DATE_IN_PAST_06_12: 0.0854814337604303\n",
      "DATE_IN_PAST_12_24: 0.0638152322457508\n",
      "DATE_IN_PAST_24_48: 0.03842903977765025\n",
      "DATE_IN_PAST_48_96: -0.007919785311778326\n",
      "DATE_IN_PAST_96_XX: 0.04077835756965205\n",
      "DEAR_FRIEND: 0.04843649500462882\n",
      "DEAR_SOMEBODY: 0.047048375472548525\n",
      "DEAR_SOMETHING: 0.03660306890313949\n",
      "DIET: 0.20295846089983485\n",
      "DIG_UP_INFO: 0.025876870884120336\n",
      "DIRECT_EMAIL: nan\n",
      "DISCLAIMER: 0.045980378164647624\n",
      "DISCLAIMER_LEGALESE: -0.015840810020721827\n",
      "DOMAIN_4U2: 0.10545435549038779\n",
      "DOMAIN_BODY: 0.06074377030511582\n",
      "DOMAIN_SUBJECT: 0.014342061356175405\n",
      "DONT_DELETE: -0.03934940799174934\n",
      "DO_IT_TODAY: 0.0858247918931776\n",
      "DRASTIC_REDUCED: 0.03660306890313951\n",
      "EARN_PER_WEEK: 0.05493331164600709\n",
      "EMAIL_ATTRIBUTION: -0.16831508735523246\n",
      "EMAIL_MARKETING: 0.13134575299244375\n",
      "EXCHANGE_SERVER: -0.050392552014411084\n",
      "EXCUSE_1: 0.2038241952259782\n",
      "EXCUSE_10: 0.18393299844995634\n",
      "EXCUSE_12: 0.04843649500462884\n",
      "EXCUSE_13: 0.054933311646007156\n",
      "EXCUSE_14: 0.2711145342269994\n",
      "EXCUSE_15: 0.1519378340086497\n",
      "EXCUSE_16: 0.14467810451650662\n",
      "EXCUSE_18: 0.0366030689031394\n",
      "EXCUSE_3: 0.24719888050635686\n",
      "EXCUSE_4: 0.05493331164600732\n",
      "EXCUSE_7: 0.1287174252543794\n",
      "EXCUSE_FUTURE: 0.10218734199860756\n",
      "EXPECT_TO_EARN: 0.054933311646007045\n",
      "EXTRA_CASH: 0.04850647582103631\n",
      "FAILURE_NOTICE_1: -0.01141548727742906\n",
      "FAILURE_NOTICE_2: -0.01614562306774555\n",
      "FAKED_IP_IN_RCVD: 0.036603068903139545\n",
      "FANTASTIC: 0.025876870884120266\n",
      "FINANCIAL: 0.0448387925942488\n",
      "FORGED_AOL_RCVD: 0.16289930221527787\n",
      "FORGED_EUDORAMAIL_RCVD: 0.018295799989749083\n",
      "FORGED_GW05_RCVD: 0.036603068903139545\n",
      "FORGED_HOTMAIL_RCVD: 0.1983531484728432\n",
      "FORGED_JUNO_RCVD: 0.05791085267650543\n",
      "FORGED_RCVD_FOUND: 0.055356665581880855\n",
      "FORGED_RCVD_TRAIL: 0.06745692391362192\n",
      "FORGED_YAHOO_RCVD: 0.25072203196549514\n",
      "FORM_W_MAILTO_ACTION: 0.07556187359947963\n",
      "FORWARD_LOOKING: 0.04092775202183204\n",
      "FOR_FREE: 0.16812858563789107\n",
      "FOR_INSTANT_ACCESS: 0.08794585466590542\n",
      "FOR_JUST_SOME_AMT: 0.12738377523584632\n",
      "FREE_ACCESS: 0.04092775202183204\n",
      "FREE_CELL_PHONE: 0.018295799989749072\n",
      "FREE_CONSULTATION: 0.0366030689031395\n",
      "FREE_DVD: 0.08401754722617502\n",
      "FREE_GRANT: 0.03660306890313937\n",
      "FREE_INVESTMENT: 0.057910852676505385\n",
      "FREE_MEMBERSHIP: 0.07096315191370582\n",
      "FREE_MONEY: 0.12050327095742451\n",
      "FREE_PASSWORD: 0.036603068903139455\n",
      "FREE_PORN: 0.09881525537548103\n",
      "FREE_QUOTE: 0.08794585466590536\n",
      "FREE_SAMPLE: 0.040927752021831985\n",
      "FREE_TRIAL: 0.11298308940097067\n",
      "FRIEND_AT_PUBLIC: 0.01829579998974911\n",
      "FROM_AND_TO_SAME_1: -0.08353519991980683\n",
      "FROM_AND_TO_SAME_2: -0.019965167822471305\n",
      "FROM_AND_TO_SAME_5: -0.06591500024342616\n",
      "FROM_AND_TO_SAME_6: 0.03610068392428118\n",
      "FROM_EGROUPS: -0.05366118879440856\n",
      "FROM_ENDS_IN_NUMS: 0.33086073562351215\n",
      "FROM_HAS_MIXED_NUMS: 0.17815823639608522\n",
      "FROM_HAS_MIXED_NUMS2: 0.07329810535235042\n",
      "FROM_MALFORMED: 0.03660306890313951\n",
      "FROM_NO_USER: 0.025876870884120298\n",
      "FROM_STARTS_WITH_NUMS: 0.051786206220007264\n",
      "FRONTPAGE: 0.12738377523584632\n",
      "FULL_REFUND: 0.06074377030511577\n",
      "FWD_MSG: -0.05267576103062633\n",
      "GAPPY_SUBJECT: 0.1339246631543228\n",
      "GAPPY_TEXT: 0.13502504358823603\n",
      "GET_IT_NOW: 0.03660306890313957\n",
      "GET_PAID: 0.054864659997664336\n",
      "GET_STARTED_NOW: 0.02587687088412032\n",
      "GIFT_CERTIFICATE: 0.07329810535235069\n",
      "GREAT_OFFER: 0.07776067450297128\n",
      "GUARANTEE: 0.09708640047405886\n",
      "GUARANTEED_100_PERCENT: 0.10383335531615907\n",
      "GUARANTEED_STUFF: 0.04092775202183199\n",
      "HAIR_LOSS: 0.14498781946670763\n",
      "HARDCORE_PORN: 0.03169587569588402\n",
      "HEADER_8BITS: 0.08198413358827175\n",
      "HGH: 0.10705147921329997\n",
      "HIDDEN_ASSETS: 0.0182957999897491\n",
      "HIDE_WIN_STATUS: 0.05493331164600715\n",
      "HOME_EMPLOYMENT: 0.0837673956144029\n",
      "HOTMAIL_FOOTER2: -0.011415487277429049\n",
      "HOT_NASTY: 0.11298308940097075\n",
      "HR_3113: 0.04483879259424877\n",
      "HR_4176: 0.031695875695884015\n",
      "HTML_50_70: 0.30347992542403446\n",
      "HTML_70_90: 0.1413558602692735\n",
      "HTML_90_100: 0.025876870884120346\n",
      "HTML_COMMENT_SAVED_URL: 0.1650095663837788\n",
      "HTML_COMMENT_UNIQUE_ID: 0.12716344585555567\n",
      "HTML_EMBEDS: 0.044838792594248916\n",
      "HTML_FONT_COLOR_BLUE: 0.30401525520802897\n",
      "HTML_FONT_COLOR_CYAN: 0.0879458546659053\n",
      "HTML_FONT_COLOR_GRAY: 0.24781598446044095\n",
      "HTML_FONT_COLOR_GREEN: 0.1637857678761444\n",
      "HTML_FONT_COLOR_MAGENTA: 0.1099367467103654\n",
      "HTML_FONT_COLOR_NAME: 0.24562557893401452\n",
      "HTML_FONT_COLOR_NOHASH: 0.11885021603601673\n",
      "HTML_FONT_COLOR_RED: 0.36004900214618435\n",
      "HTML_FONT_COLOR_UNKNOWN: 0.09353515235907038\n",
      "HTML_FONT_COLOR_UNSAFE: 0.2412989769586432\n",
      "HTML_FONT_COLOR_YELLOW: 0.13860822209419146\n",
      "HTML_FONT_FACE_BAD: 0.10987266860853662\n",
      "HTML_FONT_FACE_CAPS: 0.11170976052824161\n",
      "HTML_FONT_FACE_ODD: 0.22501125273619388\n",
      "HTML_FONT_INVISIBLE: 0.1845697708107026\n",
      "HTML_WITH_BGCOLOR: 0.19108464404673373\n",
      "HTTP_ESCAPED_HOST: 0.060743770305115775\n",
      "HTTP_USERNAME_USED: 0.20468663655838984\n",
      "HTTP_WITH_EMAIL_IN_URL: 0.1959087353605447\n",
      "IMPOTENCE: 0.07096315191370578\n",
      "INCOME: 0.018295799989749114\n",
      "INCREASE_SOMETHING: 0.025876870884120346\n",
      "INITIAL_INVEST: 0.040927752021831985\n",
      "INSTANT_ACCESS: 0.08794585466590542\n",
      "INVALID_DATE: 0.1812011447566938\n",
      "INVALID_DATE_TZ_ABSURD: 0.1750472864691886\n",
      "INVALID_MSGID: 0.0756678630957591\n",
      "INVESTMENT: 0.03660306890313945\n",
      "IN_REP_TO: -0.2907222668129454\n",
      "ITS_LEGAL: 0.044838792594248646\n",
      "JAVASCRIPT: 0.14139169806088478\n",
      "JAVASCRIPT_UNSAFE: 0.10383335531615907\n",
      "JAVASCRIPT_VERY_UNSAFE: 0.057910852676505434\n",
      "JODY: 0.044838792594248826\n",
      "JOIN_MILLIONS: 0.03169587569588404\n",
      "KNOWN_MAILING_LIST: -0.08657634652501667\n",
      "LARGE_COLLECTION: 0.05178620622000732\n",
      "LARGE_HEX: 0.07989987239645067\n",
      "LESBIAN: 0.02587687088412031\n",
      "LIMITED_TIME_ONLY: 0.16709494119400373\n",
      "LINES_OF_YELLING: 0.14027376391028068\n",
      "LINES_OF_YELLING_2: 0.09570339661841208\n",
      "LINES_OF_YELLING_3: 0.09718718660591219\n",
      "LIVE_PORN: 0.0798998723964507\n",
      "LONG_DISTANCE: 0.04092775202183199\n",
      "LOSE_POUNDS: 0.0732981053523509\n",
      "LOW_INTEREST: 0.05779849117566138\n",
      "LOW_PAYMENT: 0.0755618735994798\n",
      "LOW_PRICE: 0.12467541665978783\n",
      "MAILER_DAEMON: -0.01614562306774555\n",
      "MAILTO_LINK: 0.2529918867905423\n",
      "MAILTO_TO_REMOVE: 0.19501133501811027\n",
      "MAILTO_TO_SPAM_ADDR: 0.0738680933890471\n",
      "MAILTO_WITH_SUBJ: 0.15306715874003093\n",
      "MAILTO_WITH_SUBJ_REMOVE: 0.1287174252543794\n",
      "MAJORDOMO: -0.011415487277429068\n",
      "MANY_EXCLAMATIONS: 0.12018561233207126\n",
      "MARKETING: -0.002029848238563081\n",
      "MARKETING_PARTNERS: 0.223700198957431\n",
      "MARKET_SOLUTION: 0.03660306890313945\n",
      "MAY_BE_FORGED: 0.14264419335066925\n",
      "MEET_SINGLES: 0.04483879259424881\n",
      "MEGA_SITE: nan\n",
      "MEMBER_2: 0.1036638331980556\n",
      "MICROSOFT_EXECUTABLE: -0.011415487277429068\n",
      "MIME_BOUND_DIGITS_7: 0.004865623908187429\n",
      "MIME_BOUND_HASHES: 0.03169587569588405\n",
      "MIME_BOUND_HEX_24: 0.03169587569588404\n",
      "MIME_BOUND_MA: 0.018295799989749097\n",
      "MIME_BOUND_MIME_BOUND: 0.04092775202183207\n",
      "MIME_BOUND_OPTIN: 0.07776067450297136\n",
      "MIME_EXCESSIVE_QP: 0.06624170142300381\n",
      "MIME_HTML_NO_CHARSET: 0.20618908581548465\n",
      "MIME_LONG_LINE_QP: 0.1033085183478891\n",
      "MIME_NULL_BLOCK: -0.06759983281385441\n",
      "MIME_ODD_CASE: 0.1586001106958315\n",
      "MIME_SUSPECT_NAME: -0.01614562306774557\n",
      "MISSING_HEADERS: -0.03612691123851851\n",
      "MISSING_MIMEOLE: 0.3219613375361594\n",
      "MISSING_OUTLOOK_NAME: 0.24508606908571953\n",
      "MLM: 0.08600372051886469\n",
      "MONEY_BACK: 0.1190812827136518\n",
      "MONTH_TRIAL: 0.06345143919727263\n",
      "MORTGAGE_OBFU: 0.154960853090138\n",
      "MORTGAGE_RATES: 0.06059826137121805\n",
      "MSGID_CHARS_SPAM: 0.011930763999622796\n",
      "MSGID_CHARS_WEIRD: 0.10193838470516667\n",
      "MSGID_HAS_NO_AT: 0.05791085267650535\n",
      "MSG_ID_ADDED_BY_MTA: 0.014342061356175401\n",
      "MSG_ID_ADDED_BY_MTA_2: 0.188978602483722\n",
      "MSG_ID_ADDED_BY_MTA_3: 0.009222396759525376\n",
      "MUST_BE_18: 0.03719964112790707\n",
      "NAME_BRAND: 0.040927752021832\n",
      "NASTY_GIRLS: 0.07096315191370595\n",
      "NEW_DOMAIN_EXTENSIONS: 0.018295799989749145\n",
      "NIGERIAN_TRANSACTION_1: 0.03660306890313947\n",
      "NIGERIAN_TRANSACTION_2: 0.03169587569588405\n",
      "NONEXISTENT_CHARSET: 0.04092775202183204\n",
      "NORMAL_HTTP_TO_IP: 0.2957592591610777\n",
      "NOSPAM_INC: -0.19901229875564844\n",
      "NOT_INTENDED: 0.040927752021831985\n",
      "NOT_MLM: 0.03660306890313953\n",
      "NO_COMBINE: 0.03660306890313946\n",
      "NO_COST: 0.11140140489931893\n",
      "NO_CREDIT_CHECK: 0.040927752021832\n",
      "NO_EXPERIENCE: 0.057910852676505344\n",
      "NO_FEE: 0.1190812827136519\n",
      "NO_FORMS: 0.018295799989749135\n",
      "NO_OBLIGATION: 0.13113071401369172\n",
      "NO_QS_ASKED: 0.054933311646007\n",
      "NO_REAL_NAME: 0.1804657808532027\n",
      "NO_STRINGS: 0.06854973885448416\n",
      "OBFUSCATING_COMMENT: 0.12738377523584635\n",
      "OFFER: 0.2607538772533823\n",
      "OFFER_EXPIRE: 0.0660492654167556\n",
      "ONE_TIME: 0.03169587569588402\n",
      "ONE_TIME_MAILING: 0.07096315191370584\n",
      "ONLINE_PHARMACY: 0.09170913616134119\n",
      "ONLY_COST: 0.2114724494614178\n",
      "OPPORTUNITY: 0.0485064758210363\n",
      "OPPORTUNITY_2: 0.035109218396112585\n",
      "OPT_IN: 0.17305034777137915\n",
      "ORDER_NOW: 0.10545435549038795\n",
      "ORDER_STATUS: 0.055597828775252565\n",
      "OUTLOOK_FW_MSG: 0.04679807385552665\n",
      "PARA_A_2_C_OF_1618: 0.04092775202183202\n",
      "PATCH_CONTEXT_DIFF: -0.073388596692325\n",
      "PENIS_ENLARGE: 0.11764271750242822\n",
      "PENIS_ENLARGE2: 0.11908128271365198\n",
      "PGP_SIGNATURE: -0.03296002547637959\n",
      "PGP_SIGNATURE_2: -0.01614562306774555\n",
      "PLING_PLING: 0.061727180284937844\n",
      "PLING_QUERY: 0.3291494739333782\n",
      "PORN_4: 0.1582600029046809\n",
      "PORN_6: 0.031695875695884015\n",
      "PORN_MEMBERSHIP: 0.044838792594248736\n",
      "PORN_PASSWORD: 0.018295799989749083\n",
      "PRINT_FORM_SIGNATURE: 0.025876870884120308\n",
      "PRIORITY_NO_NAME: 0.1006640545034215\n",
      "PRIZE: nan\n",
      "PROFITS: 0.03169587569588408\n",
      "QUOTED_EMAIL_TEXT: -0.2946231973608284\n",
      "RATWARE_EGROUPS: 0.09532694196384593\n",
      "RATWARE_GROUPMAIL: 0.0371996411279071\n",
      "RATWARE_IMKTG: 0.036603068903139475\n",
      "RATWARE_JIXING: 0.025876870884120343\n",
      "RATWARE_JPFREE: 0.04483879259424882\n",
      "RATWARE_MATCHMAKER: 0.025876870884120398\n",
      "RATWARE_MMAILER: 0.04843649500462885\n",
      "RATWARE_OE_MALFORMED: 0.025876870884120308\n",
      "RATWARE_OE_PI: 0.08600372051886439\n",
      "RATWARE_SCREWUP_1: 0.018295799989749104\n",
      "RATWARE_STORM: 0.03660306890313945\n",
      "RATWARE_XMAILER: 0.03169587569588393\n",
      "READ_TO_END: 0.025876870884120454\n",
      "REFERENCES: -0.22049516819834536\n",
      "REFINANCE: 0.03719964112790707\n",
      "RELAYING_FRAME: 0.03660306890313949\n",
      "REMOVAL_INSTRUCTIONS: 0.11017823679968348\n",
      "REMOVE_IN_QUOTES: 0.0879458546659052\n",
      "REMOVE_PAGE: 0.3094490731047011\n",
      "REMOVE_SUBJ: 0.12581447497683595\n",
      "REPLY_REMOVE_SUBJECT: 0.05178620622000727\n",
      "RESENT_TO: 0.38440574023869045\n",
      "RESERVES_RIGHT: -0.011623274273902888\n",
      "RESISTANCE_IS_FUTILE: 0.04843649500462883\n",
      "REVERSE_AGING: 0.15193783400864969\n",
      "RICH: 0.01829579998974914\n",
      "RISK_FREE: 0.1364569602891399\n",
      "ROUND_THE_WORLD: 0.040927752021832034\n",
      "SALE: 0.08769301754612742\n",
      "SATISFACTION: 0.09170913616134128\n",
      "SAVE_BUCKS: 0.045021265021059687\n",
      "SAVE_MONEY: 0.14733894483566265\n",
      "SAVE_ON_INSURANCE: 0.04843649500462883\n",
      "SAVE_THOUSANDS: 0.054933311646007274\n",
      "SAVE_UP_TO: 0.1054543554903878\n",
      "SAVINGS: 0.060743770305115866\n",
      "SEARCH_ENGINE_PROMO: 0.03169587569588401\n",
      "SECTION_301: 0.057910852676505406\n",
      "SEDUCTION: 0.031695875695884015\n",
      "SEE_FOR_YOURSELF: 0.07329810535235072\n",
      "SENT_IN_COMPLIANCE: 0.07556187359947959\n",
      "SERIOUS_CASH: 0.025876870884120454\n",
      "SIGNATURE_LONG_DENSE: -0.04985275185129484\n",
      "SIGNATURE_LONG_SPARSE: -0.09337583967736016\n",
      "SIGNATURE_SHORT_DENSE: -0.31802294077337395\n",
      "SIGNATURE_SHORT_SPARSE: -0.07693171993950913\n",
      "SIGN_UP: 0.014538472202316917\n",
      "SLASH_PRICE: 0.01829579998974911\n",
      "SMTPD_IN_RCVD: 0.069317313023417\n",
      "SOCIAL_SEC_NUMBER: 0.0258768708841203\n",
      "SPAM_PHRASE_00_01: -0.6913554213925678\n",
      "SPAM_PHRASE_01_02: 0.05563885221338974\n",
      "SPAM_PHRASE_02_03: 0.012247359342165979\n",
      "SPAM_PHRASE_03_05: 0.13958508989523177\n",
      "SPAM_PHRASE_05_08: 0.2989306734214023\n",
      "SPAM_PHRASE_08_13: 0.368702016175484\n",
      "SPAM_PHRASE_13_21: 0.32432017314162914\n",
      "SPAM_PHRASE_21_34: 0.19946172879064225\n",
      "SPAM_PHRASE_34_55: 0.07556187359947973\n",
      "SPAM_PHRASE_55_XX: 0.036603068903139524\n",
      "SPAM_REDIRECTOR: 0.09532694196384586\n",
      "STOCK_PICK: 0.02587687088412033\n",
      "SUBJECT_FREQ: -0.04082140738117286\n",
      "SUBJECT_IS_LIST: 0.001049216023347129\n",
      "SUBJECT_IS_NEWS: 0.004228831446451207\n",
      "SUBJECT_MONTH: -0.12885924243804364\n",
      "SUBJECT_MONTH_2: -0.12386476310217498\n",
      "SUBJ_2_CREDIT: 0.054933311646007205\n",
      "SUBJ_ALL_CAPS: -0.052467861442834184\n",
      "SUBJ_ENDS_IN_SPACE: 0.12716344585555567\n",
      "SUBJ_FREE_CAP: 0.15968507160439946\n",
      "SUBJ_FULL_OF_8BITS: 0.09881525537548104\n",
      "SUBJ_HAS_SPACES: 0.26964848809225817\n",
      "SUBJ_HAS_UNIQ_ID: 0.2608385973680059\n",
      "SUBJ_MISSING: -0.08972174442207588\n",
      "SUBJ_REMOVE: 0.1586001106958314\n",
      "SUB_FREE_OFFER: 0.04092775202183203\n",
      "SUPERLONG_LINE: 0.13707485368498018\n",
      "SUPPLIES_LIMITED: 0.05178620622000731\n",
      "SUSPECT_LIST_HEADERS: 0.03910209896556718\n",
      "SUSPICIOUS_RECIPS: 0.0278441212431993\n",
      "TABLE_THICK_BORDER: 0.1596850716043994\n",
      "TARGETED: 0.04843649500462883\n",
      "THE_BEST_RATE: 0.07329810535235078\n",
      "THIS_AINT_SPAM: 0.057910852676505406\n",
      "TONER: 0.08401754722617509\n",
      "TO_ADDRESS_EQ_REAL: 0.1668653500395006\n",
      "TO_BE_REMOVED_REPLY: 0.05486465999766445\n",
      "TO_EMPTY: 0.06345143919727263\n",
      "TO_LOCALPART_EQ_REAL: 0.03837595061357427\n",
      "TO_MALFORMED: 0.027634906689003695\n",
      "TO_NO_USER: 0.036603068903139496\n",
      "TRACKER_ID: 0.23914512610956354\n",
      "TRACK_NUMBER: -0.011415487277429066\n",
      "UCE_MAIL_ACT: 0.04843649500462882\n",
      "UNCLAIMED_MONEY: 0.018295799989749093\n",
      "UNDISC_RECIPS: 0.06326532134996175\n",
      "UNSECURED_CREDIT: 0.05178620622000722\n",
      "UNSUB_PAGE: 0.15175044102844587\n",
      "UNSUB_SCRIPT: 0.15306715874003093\n",
      "UPPERCASE_25_50: 0.07046564799792632\n",
      "UPPERCASE_50_75: 0.08376739561440294\n",
      "URGENT_BIZ: 0.025876870884120332\n",
      "URI_IS_POUND: 0.040927752021832055\n",
      "USERNAME_IN_SUBJECT: nan\n",
      "USER_AGENT: -0.14409544714111996\n",
      "USER_AGENT_AOL: 0.11876445654583181\n",
      "USER_AGENT_GNUS_UA: nan\n",
      "USER_AGENT_IMP: -0.04573364321747188\n",
      "USER_AGENT_MACOE: -0.011415487277429049\n",
      "USER_AGENT_MOZILLA_UA: -0.060576119658280456\n",
      "USER_AGENT_MOZILLA_XM: -0.10498938559033964\n",
      "USER_AGENT_MUTT: -0.10248398201416062\n",
      "USER_AGENT_OE: 0.23747458359557264\n",
      "USER_AGENT_OUTLOOK: 0.0483282838812516\n",
      "USER_AGENT_PINE: -0.3335177522092501\n",
      "USER_AGENT_THEBAT: 0.10105185822005996\n",
      "USER_AGENT_TONLINE: -0.04121079971747415\n",
      "USER_IN_WHITELIST: -0.030221482132423684\n",
      "US_DOLLARS: 0.036603068903139545\n",
      "US_DOLLARS_2: 0.05779849117566119\n",
      "US_DOLLARS_3: 0.10218734199860788\n",
      "US_DOLLARS_4: 0.027634906689003716\n",
      "VACATION_SCAM: 0.03660306890313949\n",
      "VERY_SUSP_RECIPS: 0.045021265021059534\n",
      "VIAGRA: 0.09708640047405893\n",
      "VIAGRA_ONLINE: 0.04850647582103629\n",
      "WEB_BUGS: 0.48429020312293236\n",
      "WEIRD_PORT: 0.15722865224233262\n",
      "WE_HONOR_ALL: 0.11618695919364387\n",
      "WE_PROMISE_YOU: 0.018295799989749145\n",
      "WHILE_SUPPLIES: 0.07556187359947976\n",
      "WHILE_YOU_SLEEP: 0.06854973885448414\n",
      "WHY_WAIT: 0.0685497388544842\n",
      "WINNER_CAP: 0.027634906689003758\n",
      "WORK_AT_HOME: 0.10051508626859827\n",
      "WRINKLES: 0.06854973885448423\n",
      "X_ACCEPT_LANG: -0.22755961390204268\n",
      "X_AUTH_WARNING: 0.27466099320822673\n",
      "X_ENC_PRESENT: 0.04092775202183206\n",
      "X_LIBRARY: 0.031695875695884036\n",
      "X_LIST_UNSUBSCRIBE: 0.14498781946670788\n",
      "X_MSMAIL_PRIORITY_HIGH: 0.11440062658202783\n",
      "X_PRECEDENCE_REF: 0.025876870884120332\n",
      "X_PRIORITY_HIGH: 0.15638158690780937\n",
      "X_STORMPOST_TO: 0.03660306890313945\n",
      "X_X_PRESENT: 0.04483879259424872\n",
      "YOUR_INCOME: 0.03169587569588406\n",
      "target: 1.0\n",
      "Najwieksza korelacja: 0.6331681680008769\n",
      "Najmniejsza korelacja: -0.6913554213925678\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "correlations =  features.drop(\"target\", axis=1).apply(lambda x: x.corr(features.target))\n",
    "nans = []\n",
    "scores=[]\n",
    "for feature in features.iteritems():\n",
    "    correlation = feature[1].corr(features.target)\n",
    "    print(f\"{feature[0]}: {correlation}\")\n",
    "    \n",
    "    if np.isnan(correlation):\n",
    "        nans.append(feature[0])\n",
    "    scores.append(correlation)\n",
    "features =  features.drop(nans, axis=1)\n",
    "print(f\"Najwieksza korelacja: {max(correlations)}\")\n",
    "print(f\"Najmniejsza korelacja: {min(correlations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.06604926541675588,\n",
       " 0.10993674671036519,\n",
       " nan,\n",
       " -0.16317414215980236,\n",
       " -0.09756197756427647,\n",
       " -0.07863930730885979,\n",
       " -0.022838130478730796,\n",
       " 0.006052128698605897,\n",
       " 0.014538472202316844,\n",
       " 0.018295799989749104,\n",
       " 0.018295799989749128,\n",
       " 0.021742769057671994,\n",
       " 0.025876870884120298,\n",
       " 0.025876870884120357,\n",
       " 0.03169587569588402,\n",
       " 0.031695875695884064,\n",
       " 0.03225317721172209,\n",
       " 0.036603068903139475,\n",
       " 0.03660306890313948,\n",
       " 0.036603068903139566,\n",
       " 0.03719964112790706,\n",
       " 0.044838792594248646,\n",
       " 0.044838792594248694,\n",
       " 0.044838792594248764,\n",
       " 0.04483879259424878,\n",
       " 0.05178620622000729,\n",
       " 0.054933311646006996,\n",
       " 0.0549333116460071,\n",
       " 0.05493331164600724,\n",
       " 0.05493331164600735,\n",
       " 0.05493331164600753,\n",
       " 0.05791085267650537,\n",
       " 0.060743770305115796,\n",
       " 0.06604926541675578,\n",
       " 0.06604926541675597,\n",
       " 0.06834375753485342,\n",
       " 0.07556187359947966,\n",
       " 0.07556187359947972,\n",
       " 0.07776067450297144,\n",
       " 0.09532694196384595,\n",
       " 0.09881525537548108,\n",
       " 0.10383335531615924,\n",
       " 0.10383335531615928,\n",
       " 0.10862578007013851,\n",
       " 0.10862578007013857,\n",
       " 0.12190926268424954,\n",
       " 0.12307411589083916,\n",
       " 0.14616786074599367,\n",
       " 0.15939693788771456,\n",
       " 0.17593194340867357,\n",
       " 0.17619462866631075,\n",
       " 0.2114724494614175,\n",
       " 0.2920610758463988,\n",
       " 0.2938542940460415,\n",
       " 0.4380895953966236,\n",
       " 0.4714030493525704,\n",
       " 0.6331681680008769,\n",
       " nan,\n",
       " 0.5985798465969208,\n",
       " nan,\n",
       " -0.16831508735523246,\n",
       " -0.050392552014411084,\n",
       " -0.03934940799174934,\n",
       " -0.01614562306774555,\n",
       " -0.015840810020721827,\n",
       " -0.01141548727742906,\n",
       " -0.007919785311778326,\n",
       " 0.014342061356175405,\n",
       " 0.018295799989749083,\n",
       " 0.018295799989749124,\n",
       " 0.025876870884120266,\n",
       " 0.025876870884120336,\n",
       " 0.0366030689031394,\n",
       " 0.03660306890313949,\n",
       " 0.03660306890313951,\n",
       " 0.036603068903139545,\n",
       " 0.036603068903139545,\n",
       " 0.03842903977765025,\n",
       " 0.04077835756965205,\n",
       " 0.04092775202183204,\n",
       " 0.0448387925942488,\n",
       " 0.045980378164647624,\n",
       " 0.047048375472548525,\n",
       " 0.04843649500462882,\n",
       " 0.04843649500462884,\n",
       " 0.04850647582103631,\n",
       " 0.054933311646007045,\n",
       " 0.05493331164600709,\n",
       " 0.054933311646007156,\n",
       " 0.05493331164600732,\n",
       " 0.055356665581880855,\n",
       " 0.05791085267650543,\n",
       " 0.06074377030511582,\n",
       " 0.0638152322457508,\n",
       " 0.06745692391362192,\n",
       " 0.06856372254575058,\n",
       " 0.07556187359947963,\n",
       " 0.0854814337604303,\n",
       " 0.0858247918931776,\n",
       " 0.08794585466590542,\n",
       " 0.10218734199860756,\n",
       " 0.10545435549038779,\n",
       " 0.1287174252543794,\n",
       " 0.20295846089983485,\n",
       " nan,\n",
       " -0.19901229875564844,\n",
       " -0.06759983281385441,\n",
       " -0.03612691123851851,\n",
       " -0.01614562306774557,\n",
       " -0.011415487277429068,\n",
       " 0.004865623908187429,\n",
       " 0.009222396759525376,\n",
       " 0.011930763999622796,\n",
       " 0.014342061356175401,\n",
       " 0.018295799989749097,\n",
       " 0.018295799989749135,\n",
       " 0.018295799989749145,\n",
       " 0.03169587569588402,\n",
       " 0.03169587569588404,\n",
       " 0.03169587569588405,\n",
       " 0.03169587569588405,\n",
       " 0.03660306890313946,\n",
       " 0.03660306890313947,\n",
       " 0.03660306890313953,\n",
       " 0.03719964112790707,\n",
       " 0.040927752021831985,\n",
       " 0.040927752021832,\n",
       " 0.040927752021832,\n",
       " 0.04092775202183204,\n",
       " 0.04092775202183207,\n",
       " 0.04483879259424881,\n",
       " 0.054933311646007,\n",
       " 0.057910852676505344,\n",
       " 0.05791085267650535,\n",
       " 0.06059826137121805,\n",
       " 0.06345143919727263,\n",
       " 0.06624170142300381,\n",
       " 0.06854973885448416,\n",
       " 0.07096315191370595,\n",
       " 0.07776067450297136,\n",
       " 0.10193838470516667,\n",
       " 0.1033085183478891,\n",
       " 0.1036638331980556,\n",
       " 0.11140140489931893,\n",
       " 0.1190812827136519,\n",
       " 0.12738377523584635,\n",
       " 0.14264419335066925,\n",
       " nan,\n",
       " -0.2946231973608284,\n",
       " -0.22049516819834536,\n",
       " -0.073388596692325,\n",
       " -0.03296002547637959,\n",
       " -0.01614562306774555,\n",
       " -0.011623274273902888,\n",
       " 0.018295799989749083,\n",
       " 0.018295799989749104,\n",
       " 0.01829579998974914,\n",
       " 0.025876870884120308,\n",
       " 0.025876870884120308,\n",
       " 0.025876870884120343,\n",
       " 0.025876870884120398,\n",
       " 0.025876870884120454,\n",
       " 0.03169587569588393,\n",
       " 0.031695875695884015,\n",
       " 0.03169587569588408,\n",
       " 0.035109218396112585,\n",
       " 0.03660306890313945,\n",
       " 0.036603068903139475,\n",
       " 0.03660306890313949,\n",
       " 0.03719964112790707,\n",
       " 0.0371996411279071,\n",
       " 0.04092775202183202,\n",
       " 0.040927752021832034,\n",
       " 0.044838792594248736,\n",
       " 0.04483879259424882,\n",
       " 0.045021265021059687,\n",
       " 0.04679807385552665,\n",
       " 0.04843649500462883,\n",
       " 0.04843649500462883,\n",
       " 0.04843649500462885,\n",
       " 0.0485064758210363,\n",
       " 0.05178620622000727,\n",
       " 0.054933311646007274,\n",
       " 0.055597828775252565,\n",
       " 0.061727180284937844,\n",
       " 0.0660492654167556,\n",
       " 0.07096315191370584,\n",
       " 0.08600372051886439,\n",
       " 0.08600372051886469,\n",
       " 0.08769301754612742,\n",
       " 0.0879458546659052,\n",
       " 0.09170913616134119,\n",
       " 0.09170913616134128,\n",
       " 0.09532694196384593,\n",
       " 0.1006640545034215,\n",
       " 0.10545435549038795,\n",
       " 0.11017823679968348,\n",
       " 0.11764271750242822,\n",
       " 0.1190812827136518,\n",
       " 0.11908128271365198,\n",
       " 0.12581447497683595,\n",
       " 0.13113071401369172,\n",
       " 0.1364569602891399,\n",
       " 0.14733894483566265,\n",
       " 0.15193783400864969,\n",
       " 0.154960853090138,\n",
       " 0.1582600029046809,\n",
       " 0.1586001106958315,\n",
       " 0.17305034777137915,\n",
       " 0.1804657808532027,\n",
       " 0.188978602483722,\n",
       " 0.20618908581548465,\n",
       " 0.2114724494614178,\n",
       " 0.24508606908571953,\n",
       " 0.2607538772533823,\n",
       " 0.2957592591610777,\n",
       " 0.3094490731047011,\n",
       " 0.3219613375361594,\n",
       " 0.3291494739333782,\n",
       " nan,\n",
       " -0.6913554213925678,\n",
       " -0.3335177522092501,\n",
       " -0.31802294077337395,\n",
       " -0.2907222668129454,\n",
       " -0.22755961390204268,\n",
       " -0.14409544714111996,\n",
       " -0.12885924243804364,\n",
       " -0.12386476310217498,\n",
       " -0.10498938559033964,\n",
       " -0.10248398201416062,\n",
       " -0.09337583967736016,\n",
       " -0.08972174442207588,\n",
       " -0.08657634652501667,\n",
       " -0.08353519991980683,\n",
       " -0.07693171993950913,\n",
       " -0.06591500024342616,\n",
       " -0.060576119658280456,\n",
       " -0.05366118879440856,\n",
       " -0.05267576103062633,\n",
       " -0.052467861442834184,\n",
       " -0.04985275185129484,\n",
       " -0.04573364321747188,\n",
       " -0.04121079971747415,\n",
       " -0.04082140738117286,\n",
       " -0.030221482132423684,\n",
       " -0.019965167822471305,\n",
       " -0.01614562306774555,\n",
       " -0.011415487277429068,\n",
       " -0.011415487277429066,\n",
       " -0.011415487277429049,\n",
       " -0.011415487277429049,\n",
       " -0.002029848238563081,\n",
       " 0.001049216023347129,\n",
       " 0.004228831446451207,\n",
       " 0.012247359342165979,\n",
       " 0.014538472202316917,\n",
       " 0.018295799989749072,\n",
       " 0.018295799989749093,\n",
       " 0.0182957999897491,\n",
       " 0.01829579998974911,\n",
       " 0.01829579998974911,\n",
       " 0.018295799989749114,\n",
       " 0.018295799989749145,\n",
       " 0.025876870884120298,\n",
       " 0.0258768708841203,\n",
       " 0.02587687088412031,\n",
       " 0.02587687088412032,\n",
       " 0.02587687088412033,\n",
       " 0.025876870884120332,\n",
       " 0.025876870884120332,\n",
       " 0.025876870884120346,\n",
       " 0.025876870884120346,\n",
       " 0.025876870884120454,\n",
       " 0.027634906689003695,\n",
       " 0.027634906689003716,\n",
       " 0.027634906689003758,\n",
       " 0.0278441212431993,\n",
       " 0.03169587569588401,\n",
       " 0.031695875695884015,\n",
       " 0.031695875695884015,\n",
       " 0.03169587569588402,\n",
       " 0.031695875695884036,\n",
       " 0.03169587569588404,\n",
       " 0.03169587569588406,\n",
       " 0.03610068392428118,\n",
       " 0.03660306890313937,\n",
       " 0.03660306890313945,\n",
       " 0.03660306890313945,\n",
       " 0.03660306890313945,\n",
       " 0.036603068903139455,\n",
       " 0.03660306890313949,\n",
       " 0.036603068903139496,\n",
       " 0.0366030689031395,\n",
       " 0.03660306890313951,\n",
       " 0.036603068903139524,\n",
       " 0.036603068903139545,\n",
       " 0.03660306890313957,\n",
       " 0.03837595061357427,\n",
       " 0.03910209896556718,\n",
       " 0.040927752021831985,\n",
       " 0.040927752021831985,\n",
       " 0.04092775202183199,\n",
       " 0.04092775202183199,\n",
       " 0.04092775202183203,\n",
       " 0.04092775202183204,\n",
       " 0.040927752021832055,\n",
       " 0.04092775202183206,\n",
       " 0.044838792594248646,\n",
       " 0.04483879259424872,\n",
       " 0.04483879259424877,\n",
       " 0.044838792594248826,\n",
       " 0.044838792594248916,\n",
       " 0.045021265021059534,\n",
       " 0.0483282838812516,\n",
       " 0.04843649500462882,\n",
       " 0.04843649500462883,\n",
       " 0.04850647582103629,\n",
       " 0.05178620622000722,\n",
       " 0.051786206220007264,\n",
       " 0.05178620622000731,\n",
       " 0.05178620622000732,\n",
       " 0.054864659997664336,\n",
       " 0.05486465999766445,\n",
       " 0.05493331164600715,\n",
       " 0.054933311646007205,\n",
       " 0.05563885221338974,\n",
       " 0.05779849117566119,\n",
       " 0.05779849117566138,\n",
       " 0.057910852676505385,\n",
       " 0.057910852676505406,\n",
       " 0.057910852676505406,\n",
       " 0.057910852676505434,\n",
       " 0.06074377030511577,\n",
       " 0.060743770305115775,\n",
       " 0.060743770305115866,\n",
       " 0.06326532134996175,\n",
       " 0.06345143919727263,\n",
       " 0.06854973885448414,\n",
       " 0.0685497388544842,\n",
       " 0.06854973885448423,\n",
       " 0.069317313023417,\n",
       " 0.07046564799792632,\n",
       " 0.07096315191370578,\n",
       " 0.07096315191370582,\n",
       " 0.07329810535235042,\n",
       " 0.07329810535235069,\n",
       " 0.07329810535235072,\n",
       " 0.07329810535235078,\n",
       " 0.0732981053523509,\n",
       " 0.0738680933890471,\n",
       " 0.07556187359947959,\n",
       " 0.07556187359947973,\n",
       " 0.07556187359947976,\n",
       " 0.0755618735994798,\n",
       " 0.0756678630957591,\n",
       " 0.07776067450297128,\n",
       " 0.07989987239645067,\n",
       " 0.0798998723964507,\n",
       " 0.08198413358827175,\n",
       " 0.0837673956144029,\n",
       " 0.08376739561440294,\n",
       " 0.08401754722617502,\n",
       " 0.08401754722617509,\n",
       " 0.0879458546659053,\n",
       " 0.08794585466590536,\n",
       " 0.08794585466590542,\n",
       " 0.09353515235907038,\n",
       " 0.09532694196384586,\n",
       " 0.09570339661841208,\n",
       " 0.09708640047405886,\n",
       " 0.09708640047405893,\n",
       " 0.09718718660591219,\n",
       " 0.09881525537548103,\n",
       " 0.09881525537548104,\n",
       " 0.10051508626859827,\n",
       " 0.10105185822005996,\n",
       " 0.10218734199860788,\n",
       " 0.10383335531615907,\n",
       " 0.10383335531615907,\n",
       " 0.1054543554903878,\n",
       " 0.10705147921329997,\n",
       " 0.10987266860853662,\n",
       " 0.1099367467103654,\n",
       " 0.11170976052824161,\n",
       " 0.11298308940097067,\n",
       " 0.11298308940097075,\n",
       " 0.11440062658202783,\n",
       " 0.11618695919364387,\n",
       " 0.11876445654583181,\n",
       " 0.11885021603601673,\n",
       " 0.12018561233207126,\n",
       " 0.12050327095742451,\n",
       " 0.12467541665978783,\n",
       " 0.12716344585555567,\n",
       " 0.12716344585555567,\n",
       " 0.12738377523584632,\n",
       " 0.12738377523584632,\n",
       " 0.1287174252543794,\n",
       " 0.13134575299244375,\n",
       " 0.1339246631543228,\n",
       " 0.13502504358823603,\n",
       " 0.13707485368498018,\n",
       " 0.13860822209419146,\n",
       " 0.13958508989523177,\n",
       " 0.14027376391028068,\n",
       " 0.1413558602692735,\n",
       " 0.14139169806088478,\n",
       " 0.14467810451650662,\n",
       " 0.14498781946670763,\n",
       " 0.15175044102844587,\n",
       " 0.15306715874003093,\n",
       " 0.23914512610956354,\n",
       " nan,\n",
       " nan,\n",
       " 0.14498781946670788,\n",
       " 0.1519378340086497,\n",
       " 0.15306715874003093,\n",
       " 0.15638158690780937,\n",
       " 0.15722865224233262,\n",
       " 0.1586001106958314,\n",
       " 0.1596850716043994,\n",
       " 0.15968507160439946,\n",
       " 0.16289930221527787,\n",
       " 0.1637857678761444,\n",
       " 0.1650095663837788,\n",
       " 0.1668653500395006,\n",
       " 0.16709494119400373,\n",
       " 0.16812858563789107,\n",
       " 0.1750472864691886,\n",
       " 0.17815823639608522,\n",
       " 0.1812011447566938,\n",
       " 0.18393299844995634,\n",
       " 0.1845697708107026,\n",
       " 0.19108464404673373,\n",
       " 0.19501133501811027,\n",
       " 0.1959087353605447,\n",
       " 0.1983531484728432,\n",
       " 0.19946172879064225,\n",
       " 0.2038241952259782,\n",
       " 0.20468663655838984,\n",
       " 0.223700198957431,\n",
       " 0.22501125273619388,\n",
       " 0.23747458359557264,\n",
       " 0.2412989769586432,\n",
       " 0.24562557893401452,\n",
       " 0.24719888050635686,\n",
       " 0.24781598446044095,\n",
       " 0.25072203196549514,\n",
       " 0.2529918867905423,\n",
       " 0.2608385973680059,\n",
       " 0.26964848809225817,\n",
       " 0.2711145342269994,\n",
       " 0.27466099320822673,\n",
       " 0.2989306734214023,\n",
       " 0.30347992542403446,\n",
       " 0.30401525520802897,\n",
       " 0.32432017314162914,\n",
       " 0.33086073562351215,\n",
       " 0.36004900214618435,\n",
       " 0.368702016175484,\n",
       " 0.38440574023869045,\n",
       " 0.48429020312293236,\n",
       " 1.0]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACT_NOW</th>\n",
       "      <th>ADULT_SITE</th>\n",
       "      <th>ADVERT_CODE</th>\n",
       "      <th>ADVERT_CODE2</th>\n",
       "      <th>ALL_CAPS_HEADER</th>\n",
       "      <th>ALL_CAP_PORN</th>\n",
       "      <th>ALL_NATURAL</th>\n",
       "      <th>AMATEUR_PORN</th>\n",
       "      <th>AMAZING</th>\n",
       "      <th>AMAZING_STUFF</th>\n",
       "      <th>...</th>\n",
       "      <th>X_AUTH_WARNING</th>\n",
       "      <th>X_ENC_PRESENT</th>\n",
       "      <th>X_LIBRARY</th>\n",
       "      <th>X_LIST_UNSUBSCRIBE</th>\n",
       "      <th>X_MSMAIL_PRIORITY_HIGH</th>\n",
       "      <th>X_PRECEDENCE_REF</th>\n",
       "      <th>X_PRIORITY_HIGH</th>\n",
       "      <th>X_STORMPOST_TO</th>\n",
       "      <th>X_X_PRESENT</th>\n",
       "      <th>YOUR_INCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 454 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACT_NOW  ADULT_SITE  ADVERT_CODE  ADVERT_CODE2  ALL_CAPS_HEADER  \\\n",
       "0        0           0            0             0                0   \n",
       "1        0           0            0             0                0   \n",
       "2        0           0            0             0                0   \n",
       "3        0           0            0             0                0   \n",
       "4        0           0            0             0                0   \n",
       "\n",
       "   ALL_CAP_PORN  ALL_NATURAL  AMATEUR_PORN  AMAZING  AMAZING_STUFF  ...  \\\n",
       "0             0            0             0        0              0  ...   \n",
       "1             0            0             0        0              0  ...   \n",
       "2             0            0             0        0              0  ...   \n",
       "3             0            0             0        0              0  ...   \n",
       "4             0            0             0        0              0  ...   \n",
       "\n",
       "   X_AUTH_WARNING  X_ENC_PRESENT  X_LIBRARY  X_LIST_UNSUBSCRIBE  \\\n",
       "0               1              0          0                   0   \n",
       "1               0              0          0                   0   \n",
       "2               0              0          0                   0   \n",
       "3               1              0          0                   0   \n",
       "4               1              0          0                   0   \n",
       "\n",
       "   X_MSMAIL_PRIORITY_HIGH  X_PRECEDENCE_REF  X_PRIORITY_HIGH  X_STORMPOST_TO  \\\n",
       "0                       0                 0                0               0   \n",
       "1                       0                 0                0               0   \n",
       "2                       0                 0                0               0   \n",
       "3                       0                 0                0               0   \n",
       "4                       0                 0                0               0   \n",
       "\n",
       "   X_X_PRESENT  YOUR_INCOME  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "\n",
       "[5 rows x 454 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = features['target']\n",
    "features.drop('target', axis = 1, inplace=True)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9822546972860126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.991364  0.008636\n",
      "0  0.031662  0.968338\n"
     ]
    }
   ],
   "source": [
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def describe_results(y_test, y_predict):\n",
    "    \n",
    "    print(F\"Acc: {accuracy_score(y_test, y_predict)}\")\n",
    "    #, recall of the positive class is also known as “sensitivity”; recall of the negative class is “specificity”.\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print(\"Macierz konfuzji\")\n",
    "    print(pd.DataFrame(\n",
    "            confusion_matrix(y_test, y_predict,normalize='true'),\n",
    "            columns=['1', '0'],\n",
    "            index=['1', '0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance ratio by Principal Component  1  :  0.12254469137417344\n",
      "Explained Variance ratio by Principal Component  2  :  0.0418203817320791\n",
      "Explained Variance ratio by Principal Component  3  :  0.03764319207928961\n",
      "Explained Variance ratio by Principal Component  4  :  0.02832703333464853\n",
      "Explained Variance ratio by Principal Component  5  :  0.025229996243784632\n",
      "Explained Variance ratio by Principal Component  6  :  0.02464951479262506\n",
      "Explained Variance ratio by Principal Component  7  :  0.02311889944890557\n",
      "Explained Variance ratio by Principal Component  8  :  0.01885048725184086\n",
      "Explained Variance ratio by Principal Component  9  :  0.016680491977920906\n",
      "Explained Variance ratio by Principal Component  10  :  0.015689069731580327\n",
      "Explained Variance ratio by Principal Component  11  :  0.014995038154819154\n",
      "Explained Variance ratio by Principal Component  12  :  0.014466017498672587\n",
      "Explained Variance ratio by Principal Component  13  :  0.014043040794612105\n",
      "Explained Variance ratio by Principal Component  14  :  0.013404689963027672\n",
      "Explained Variance ratio by Principal Component  15  :  0.013236929096083271\n",
      "Explained Variance ratio by Principal Component  16  :  0.01237234240383749\n",
      "Explained Variance ratio by Principal Component  17  :  0.012150549378605052\n",
      "Explained Variance ratio by Principal Component  18  :  0.011697527765825954\n",
      "Explained Variance ratio by Principal Component  19  :  0.0111943752650584\n",
      "Explained Variance ratio by Principal Component  20  :  0.010654201994010884\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pca = PCA(n_components = 20)\n",
    "pca_vectors = pca.fit_transform(dataset)\n",
    "for index, var in enumerate(pca.explained_variance_ratio_):\n",
    "    print(\"Explained Variance ratio by Principal Component \", (index+1), \" : \", var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,8))\n",
    "sns.scatterplot(x=pca_vectors[:, 0], y=pca_vectors[:, 1], hue=label)\n",
    "plt.title('Principal Components vs Class distribution', fontsize=16)\n",
    "plt.ylabel('Principal Component 2', fontsize=16)\n",
    "plt.xlabel('Principal Component 1', fontsize=16)\n",
    "plt.xticks(rotation='vertical');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9530271398747391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       579\n",
      "           1       0.94      0.94      0.94       379\n",
      "\n",
      "    accuracy                           0.95       958\n",
      "   macro avg       0.95      0.95      0.95       958\n",
      "weighted avg       0.95      0.95      0.95       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.958549  0.041451\n",
      "0  0.055409  0.944591\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 430)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_predict = model.predict(X_test_pca)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9812108559498957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       579\n",
      "           1       0.98      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.987910  0.012090\n",
      "0  0.029024  0.970976\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9853862212943633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.99       958\n",
      "   macro avg       0.99      0.98      0.98       958\n",
      "weighted avg       0.99      0.99      0.99       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.994819  0.005181\n",
      "0  0.029024  0.970976\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9791231732776617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       579\n",
      "           1       0.99      0.96      0.97       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.993092  0.006908\n",
      "0  0.042216  0.957784\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "model = xgb.XGBClassifier(n_estimators=5000,learning_rate=0.02)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.975991649269311\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       579\n",
      "           1       0.98      0.96      0.97       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.97      0.97       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.986183  0.013817\n",
      "0  0.039578  0.960422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model = AdaBoostClassifier(n_estimators=5000)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9822546972860126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       579\n",
      "           1       0.99      0.96      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.039578  0.960422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9812108559498957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       579\n",
      "           1       0.98      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.987910  0.012090\n",
      "0  0.029024  0.970976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomasz/.local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd',  random_state=21,tol=0.000000001)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9822546972860126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       579\n",
      "           1       0.99      0.96      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.039578  0.960422\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.918580375782881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94       579\n",
      "           1       1.00      0.79      0.89       379\n",
      "\n",
      "    accuracy                           0.92       958\n",
      "   macro avg       0.94      0.90      0.91       958\n",
      "weighted avg       0.93      0.92      0.92       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  1.000000  0.000000\n",
      "0  0.205805  0.794195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9592901878914405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       579\n",
      "           1       0.97      0.93      0.95       379\n",
      "\n",
      "    accuracy                           0.96       958\n",
      "   macro avg       0.96      0.95      0.96       958\n",
      "weighted avg       0.96      0.96      0.96       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.981002  0.018998\n",
      "0  0.073879  0.926121\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9853862212943633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.99       958\n",
      "   macro avg       0.99      0.98      0.98       958\n",
      "weighted avg       0.99      0.99      0.99       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.031662  0.968338\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0:0.9, 1:1.1})\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9822546972860126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       579\n",
      "           1       0.99      0.96      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.039578  0.960422\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0:0.95, 1:0.5})\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9843423799582464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.99      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.994819  0.005181\n",
      "0  0.031662  0.968338\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0:1.05, 1:0.95})\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9822546972860126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       579\n",
      "           1       0.99      0.96      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.98      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.039578  0.960422\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(class_weight={0:1.1, 1:0.9})\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9144050104384134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       579\n",
      "           1       0.89      0.90      0.89       379\n",
      "\n",
      "    accuracy                           0.91       958\n",
      "   macro avg       0.91      0.91      0.91       958\n",
      "weighted avg       0.91      0.91      0.91       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.924007  0.075993\n",
      "0  0.100264  0.899736\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 400)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_pca, y_train)\n",
    "y_predict = model.predict(X_test_pca)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9843423799582464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.99      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.994819  0.005181\n",
      "0  0.031662  0.968338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "trans = SelectFromModel(model, threshold='median')\n",
    "transofred_train_data = trans.fit_transform(X_train, y_train)\n",
    "transofred_test_data = trans.transform(X_test)\n",
    "\n",
    "model.fit(transofred_train_data, y_train)\n",
    "y_predict = model.predict(transofred_test_data)\n",
    "describe_results(y_test, y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9843423799582464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       579\n",
      "           1       0.99      0.97      0.98       379\n",
      "\n",
      "    accuracy                           0.98       958\n",
      "   macro avg       0.99      0.98      0.98       958\n",
      "weighted avg       0.98      0.98      0.98       958\n",
      "\n",
      "Macierz konfuzji\n",
      "          1         0\n",
      "1  0.996546  0.003454\n",
      "0  0.034301  0.965699\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "model = BaggingClassifier(RandomForestClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "describe_results(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
